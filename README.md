# Argos translate model licenses

Listing of the sources used in the Argos translate models, and their respective licenses. Sources listed here are colected from README.md of each model.

Columns that come from https://www.argosopentech.com/argospm/index/ : From,To,Download,From code,To code,Package version,Argos version,zip name

Columns that come from model’s README.md: Open Subtitles, UNPC, ...
Below name of the source (for example "Open Subtitles") there is license restriction that I found in the documentation of the respective data source (for example that citing of source is required).

After this table there is description of sources.
 
|  |  |  |  |  |  |  |  | Open Subtitles | UNPC | Stanza | OPUS | ParaCrawl | WikiExtract | WikiMatrix | Beyond | Common Crawl | CCMatrix | CCAligned | EU Bookshop | OPUS-MT | Gourmet | OPUS DGT | OPUS EOPC | other|
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| From | To | Download | From code | To code | Package version | Argos version | zip name | Cite | Public domain | Apache 2.0 | O? | CC0 | CC-BY-SA GFDL |  CC-BY-SA | B? | C? | Citing | Citing | Citing | CC-BY 4.0 Citing | CC0 | citing | citing | |
| Albanian | English | get | sq | en | 1.9 | 1.9.0 | translate-sq_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Arabic | English | get | ar | en | 1 | 1 | ar_en | x | x | x |  |  |  |  |  |  |  |  |  |  |  |  |  | |
| Azerbaijani | English | get | az | en | 1.5 | 1.5 | translate-az_en-1_5 |  |  | x | x |  | x | x |  |  | x |  |  |  | x |  |  | EMNLP 2020, reimers-gurevych-2020-making, el-kishky-etal-2021-xlent|
| Basque | English | get | eu | en | 1.9 | 1.9 | translate-eu_en-1_9 |  |  | x | x |  | x |  |  |  |  |  |  |  |  |  |  | |
| Bengali | English | get | bn | en | 1.9 | 1.9.0 | translate-bn_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Bulgarian | English | get | bg | en | 1.9 | 1.9.0 | translate-bg_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Catalan | English | get | ca | en | 1.7 | 1.5 | translate-ca_en-1_7 |  |  | x | x |  | x |  |  |  |  |  |  |  |  |  |  | |
| Chinese (traditional) | English | get | zt | en | 1.9 | 1.9.0 | translate-zt_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Chinese | English | get | zh | en | 1.9 | 1.9.0 | translate-zh_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Czech | English | get | cs | en | 1.9.6 | 1.9.6 | translate-cs_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Danish | English | get | da | en | 1.9 | 1.9.0 | translate-da_en-1_3 | x |  | x | x | x | x | x |  |  |  |  |  |  |  |  |  | EMNLP 2020|
| Dutch | English | get | nl | en | 1.8 | 1.8 | translate-nl_en-1_8 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Albanian | get | en | sq | 1.9 | 1.9.0 | translate-en_sq-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Arabic | get | en | ar | 1 | 1 | en_ar | x | x | x |  |  |  |  |  |  |  |  |  |  |  |  |  | |
| English | Azerbaijani | get | en | az | 1.5 | 1.5 | translate-en_az-1_5 |  |  | x | x |  | x |  |  |  | x |  |  |  | x |  |  | EMNLP 2020, el-kishky-etal-2021-xlent|
| English | Basque | get | en | eu | 1.9 | 1.9 | translate-en_eu-1_9 |  |  | x | x |  | x |  |  |  |  |  |  |  |  |  |  | |
| English | Bengali | get | en | bn | 1.9 | 1.9.0 | translate-en_bn-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Bulgarian | get | en | bg | 1.9 | 1.9.0 | translate-en_bg-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Catalan | get | en | ca | 1.9 | 1.9.0 | translate-en_ca-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Chinese | get | en | zh | 1.9 | 1.9.0 | translate-en_zh-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Chinese (traditional) | get | en | zt | 1.9 | 1.9.0 | translate-en_zt-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Czech | get | en | cs | 1.9.6 | 1.9.0 | translate-en_cs-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Danish | get | en | da | 1.9 | 1.9.0 | translate-en_da-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Dutch | get | en | nl | 1.8 | 1.8 | translate-en_nl-1_8 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Esperanto | get | en | eo | 1.5 | 1.5 | translate-en_eo-1_5 | x |  | x | x |  | x | x |  |  | x |  |  |  |  |  |  | el-kishky-etal-2021-xlent|
| English | Estonian | get | en | et | 1.9 | 1.9.0 | translate-en_et-1_9 | x |  | x | x |  | x | x |  |  | x |  | x |  |  | x | x | EOPC(CC-BY-SA), OPUS Europarl, OPUS ELRC-4271-NTEU_TierA (CC-BY-SA-4.0)|
| English | Finnish | get | en | fi | 1.9 | 1.9.0 | en_fi |  |  | x | x |  | x | x | x |  |  |  |  |  |  |  |  | |
| English | French | get | en | fr | 1.9 | 1.9.0 | translate-en_fr-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Galician | get | en | gl | 1.9 | 1.9 | translate-en_gl-1_9 |  |  | x | x |  | x |  |  |  |  |  |  |  |  |  |  | |
| English | German | get | en | de | 1 | 1 | en_de |  |  | x | x |  |  |  |  |  |  |  |  |  |  |  |  | |
| English | Greek | get | en | el | 1.9 | 1.9.0 | translate-en_el-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Hebrew | get | en | he | 1.5 | 1.5 | translate-en_he-1_5 |  |  | x | x |  | x | x | x |  | x |  |  |  |  |  |  | el-kishky-etal-2021-xlent,EMNLP 2020|
| English | Hindi | get | en | hi | 1.1 | 1.1 | en_hi |  |  | x | x |  | x | x | x |  |  | x |  |  |  |  |  | |
| English | Hungarian | get | en | hu | 1.9 | 1.9.0 | en_hu |  |  | x | x |  | x | x |  |  |  | x |  |  |  |  |  | |
| English | Indonesian | get | en | id | 1.9 | 1.9.0 | en_id |  |  | x | x |  | x | x |  |  |  | x |  |  |  |  |  | |
| English | Irish | get | en | ga | 1.1 | 1.1 | en_ga |  |  | x | x | x | x |  |  |  |  |  |  |  |  |  |  | |
| English | Italian | get | en | it | 1 | 1 | en_it | x |  | x |  | x |  | x |  |  |  |  | x |  |  |  |  | |
| English | Japanese | get | en | ja | 1.1 | 1.1 | en_ja | x |  | x | x |  | x | x |  |  |  | x |  |  |  |  |  | |
| English | Korean | get | en | ko | 1.1 | 1.1 | en_ko | x |  | x | x |  | x | x |  |  |  | x |  |  |  |  |  | |
| English | Latvian | get | en | lv | 1.9 | 1.9.0 | translate-en_lv-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Lithuanian | get | en | lt | 1.9 | 1.9.0 | translate-en_lt-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Malay | get | en | ms | 1.9 | 1.9.0 | translate-en_ms-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Norwegian | get | en | nb | 1.9 | 1.9.0 | translate-en_nb-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Persian | get | en | fa | 1.5 | 1.5 | translate-en_fa-1_5 | x |  | x | x |  | x | x |  |  | x |  |  |  |  |  |  | MIZAN(CC-BY), el-kishky-etal-2021-xlent,EMNLP 2020|
| English | Polish | get | en | pl | 1.9 | 1.9.0 | translate-en_pl-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Portuguese | get | en | pt | 1.9 | 1.9 | en_pt | x |  | x |  | x |  | x |  |  |  |  | x |  |  |  |  | |
| English | Portuguese (Brazil) | get | en | pb | 1.9 | 1.9 | translate-en_pb-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Romanian | get | en | ro | 1.9 | 1.9.0 | translate-en_ro-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Russian | get | en | ru | 1.9 | 1.9 | translate-en_ru-1_9 | x |  | x | x | x | x | x |  |  | x |  |  |  |  |  |  | OPUS GlobalVoices(cite), OPUS MultiUN(cite), OPUS News-Commentary(cite), OPUS QED (research only,cite), OPUS Tatoeba(credit),OPUS TED2013(BY-NC-ND),OPUS TED2020(BY-NC-ND)|
| English | Slovak | get | en | sk | 1.9 | 1.9.0 | translate-en_sk-1_5 | x |  | x | x |  | x | x |  |  |  | x |  |  |  |  |  | NODALIDA 2017,el-kishky-etal-2021-xlent|
| English | Slovenian | get | en | sl | 1.9 | 1.9.0 | translate-en_sl-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Spanish | get | en | es | 1 | 1 | en_es | x | x | x |  | x |  |  |  |  |  |  |  |  |  |  |  | |
| English | Swedish | get | en | sv | 1.5 | 1.5 | en_sv |  |  | x | x |  | x | x | x |  | x | x |  |  |  |  |  | |
| English | Tagalog | get | en | tl | 1.9 | 1.9.0 | translate-en_tl-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Thai | get | en | th | 1.9 | 1.9.0 | translate-en_th-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| English | Turkish | get | en | tr | 1.5 | 1.5 | translate-en_tr-1_5 |  |  | x | x |  | x | x |  |  | x |  |  |  | x |  |  | emnlp-2020-main,reimers-gurevych-2020-making,el-kishky-etal-2021-xlent|
| English | Ukranian | get | en | uk | 1.4 | 1.4 | en_uk |  |  | x | x |  | x | x |  |  |  | x |  |  |  |  |  | |
| English | Urdu | get | en | ur | 1.9 | 1.9 | en_ur |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Esperanto | English | get | eo | en | 1.5 | 1.5 | translate-eo_en-1_5 | x |  | x | x |  | x | x |  |  | x |  |  |  |  |  |  | el-kishky-etal-2021-xlent|
| Estonian | English | get | et | en | 1.9 | 1.9.0 | translate-et_en-1_9 | x |  | x | x |  | x | x |  |  | x |  | x |  |  |  |  | OPUS DGT(cite),OPUS EOPC(CC-BY-SA,cite),OPUS Europarl, OPUS ELRC-4271-NTEU_TierA (CC-BY-SA-4.0)|
| Finnish | English | get | fi | en | 1.9 | 1.9.0 | fi_en |  |  | x | x |  | x | x | x |  | x |  |  |  |  |  |  | |
| French | English | get | fr | en | 1.9 | 1.9.0 | translate-fr_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Galician | English | get | gl | en | 1.9 | 1.9 | translate-gl_en-1_9 |  |  | x | x |  | x |  |  |  |  |  |  |  |  |  |  | |
| German | English | get | de | en | 1 | 1 | de_en |  |  | x | x |  |  |  |  |  |  |  |  |  |  |  |  | |
| Greek | English | get | el | en | 1.9 | 1.9.0 | translate-el_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Hebrew | English | get | he | en | 1.5 | 1.5 | translate-he_en-1_5 |  |  | x | x |  | x | x | x |  | x |  |  |  |  |  |  | el-kishky-etal-2021-xlent,EMNLP 2020|
| Hindi | English | get | hi | en | 1.1 | 1.1 | hi_en |  |  | x | x |  | x | x |  |  |  | x |  |  |  |  |  | |
| Hungarian | English | get | hu | en | 1.9 | 1.9.0 | hu_en |  |  | x | x |  | x | x | x |  | x | x |  |  |  |  |  | |
| Indonesian | English | get | id | en | 1.9 | 1.9.0 | id_en |  |  | x | x |  | x | x |  |  |  | x |  |  |  |  |  | |
| Irish | English | get | ga | en | 1.1 | 1.1 | ga_en |  |  | x | x | x | x |  |  |  |  |  |  |  |  |  |  | |
| Italian | English | get | it | en | 1 | 1 | it_en | x |  | x |  | x |  | x |  |  |  |  | x |  |  |  |  | |
| Japanese | English | get | ja | en | 1.1 | 1.1 | ja_en | x |  | x | x |  | x | x |  |  |  | x |  |  |  |  |  | |
| Korean | English | get | ko | en | 1.1 | 1.1 | ko_en | x |  | x | x |  | x | x |  |  |  | x |  |  |  |  |  | |
| Latvian | English | get | lv | en | 1.9 | 1.9.0 | translate-lv_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Lithuanian | English | get | lt | en | 1.9 | 1.9.0 | translate-lt_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Malay | English | get | ms | en | 1.9 | 1.9.0 | translate-ms_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Norwegian | English | get | nb | en | 1.9 | 1.9.0 | translate-nb_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Persian | English | get | fa | en | 1.5 | 1.5 | translate-fa_en-1_5 | x |  | x | x |  | x | x |  |  | x |  |  |  |  |  |  | wolk_marasek_building_2014,MIZAN(CC-BY),el-kishky-etal-2021-xlent,emnlp-2020-main|
| Polish | English | get | pl | en | 1.9 | 1.9.0 | translate-pl_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Portuguese (Brazil) | English | get | pb | en | 1.9 | 1.9 | translate-pb_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Portuguese | English | get | pt | en | 1.9 | 1.9.0 | pt_en | x |  | x |  | x |  | x |  |  |  |  | x |  |  |  |  | |
| Portuguese | Spanish | get | pt | es | 1 | 1 | translate-pt_es-1_0 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | nothing stated|
| Romanian | English | get | ro | en | 1.9 | 1.9.0 | translate-ro_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Russian | English | get | ru | en | 1.9 | 1.9 | translate-ru_en-1_9 | x |  | x | x | x | x | x |  |  |  |  |  |  |  |  |  | OPUS GlobalVoices(cite), OPUS MultiUN(cite), OPUS News-Commentary(cite), OPUS QED (research only,cite), OPUS Tatoeba(credit),OPUS TED2013(BY-NC-ND),OPUS TED2020(BY-NC-ND)|
| Slovak | English | get | sk | en | 1.9 | 1.9.0 | translate-sk_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Slovenian | English | get | sl | en | 1.9 | 1.9.0 | translate-sl_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Spanish | English | get | es | en | 1.9 | 1.9.0 | es_en | x | x | x |  | x |  |  |  |  |  |  |  |  |  |  |  | |
| Spanish | Portuguese | get | es | pt | 1 | 1 | translate-es_pt-1_0 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  | nothing stated|
| Swedish | English | get | sv | en | 1.5 | 1.5 | sv_en |  |  | x | x |  | x | x | x |  | x | x |  |  |  |  |  | |
| Tagalog | English | get | tl | en | 1.9 | 1.9.0 | translate-tl_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Thai | English | get | th | en | 1.9 | 1.9.0 | translate-th_en-1_9 |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |
| Turkish | English | get | tr | en | 1.5 | 1.5 | translate-tr_en-1_5 |  |  | x | x |  | x |  |  |  |  |  |  |  |  |  |  | emnlp-2020-main|
| Ukrainian | English | get | uk | en | 1.9 | 1.9.0 | uk_en |  |  | x | x |  | x | x |  |  |  | x |  |  |  |  |  | |
| Urdu | English | get | ur | en | 1.9 | 1.9 | ur_en |  |  |  |  |  |  |  |  |  |  |  |  | x |  |  |  | |

# Sources

## Source notes

Sources where license is not clear: OPUS (O?), Beyond (B?), CommonCrawl (C?), wolk_marasek_building_2014, el-kishky-etal-2021-xlent, emnlp-2020-main, NODALIDA 2017, reimers-gurevych-2020-making

Sources that are not free (non-commercial, research only): QED (research only,cite), TED2013 (BY-NC-ND), TED2020(BY-NC-ND)

Some of these non-clear and non-free are also part of OPUS corpora, thus could be used in data source "OPUS".

## Source list

OPUS (O?, citing)
	Trained on data from the Opus.
	
	Broad, unknown datasets from OPUS. It is not clear which models of the corpora were used; thus it is not clear what is license restriction of used data.
	Would be helpful to gather all licenses of all sources to find the 'most strict license'.

	Please, cite the following LREC 2012 paper when using OPUS and also acknowledge corpus-specific references as specified in the resource-specific information and documentation! 
	tiedemann-2012-parallel = https://aclanthology.org/L12-1246/

OPUS OpenSubtitles (citing)
	Trained on [OpenSubtitles](opus.nlpl.eu/OpenSubtitles.php)
	
	https://opus.nlpl.eu/OpenSubtitles/corpus/version/OpenSubtitles
	Please cite the following article if you use any part of the corpus in your own work:
	P. Lison and J. Tiedemann, 2016, OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles. In Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016)
	https://aclanthology.org/L16-1147/
	"We only offer files that we believe we are free to redistribute"
	
OPUS UNPC (public domain)
	[UNPC](http://opus.nlpl.eu/UNPC.php) parallel corpuses compiled by [Opus](http://opus.nlpl.eu/index.php)
	
	United Nations Parallel Corpus
	https://opus.nlpl.eu/UNPC/corpus/version/UNPC
	For references, please cite this reference: Ziemski, M., Junczys-Dowmunt, M., and Pouliquen, B., (2016), The United Nations Parallel Corpus, Language Resources and Evaluation (LREC’16), Portorož, Slovenia, May 2016. https://cms.unov.org/UNCorpus/Content/Doc/un.pdf
	"We only offer files that we believe we are free to redistribute"
	https://www.un.org/dgacm/en/content/uncorpus = public domain

OPUS ParaCrawl (CC0)
	https://paracrawl.eu/
	Please, acknowledge the ParaCrawl project at http://paracrawl.eu. This version is derived from the original release at their website adjusted for redistribution via the OPUS corpus collection. Please, acknowledge OPUS as well for this service. 
	CC0
	
Stanza (Apache 2.0)
	Includes pretrained models from [Stanza](https://github.com/stanfordnlp/stanza/blob/master/LICENSE).

	https://github.com/stanfordnlp/stanza/blob/main/LICENSE => Apache 2.0

Wiktextract (CC-BY-SA,GFDL)
	https://github.com/tatuylonen/wiktextract
	tool itself: MIT

	https://en.wiktionary.org/wiki/Wiktionary:Copyrights
	CC-BY-SA + GFDL
	Permission is granted to copy, distribute and/or modify the text of all Wiktionary entries under the terms of the Creative Commons Attribution-ShareAlike 4.0 International License, and the GNU Free Documentation License, Version 1.1 or any later version published by the Free Software Foundation; with no Invariant Sections, with no Front-Cover Texts, and with no Back-Cover Texts. 

WikiMatrix (CC-BY-SA)
	https://github.com/facebookresearch/LASER/tree/main/tasks/WikiMatrix
	Credits: Holger Schwenk, Vishrav Chaudhary, Shuo Sun, Hongyu Gong and Paco Guzman, WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from Wikipedia, arXiv, July 11 2019.
	CC-BY-SA

Beyond (B?)
	Beyond English-Centric Multilingual Machine Translation
	It is not known why this work is credited, what is the dataset source. 
	It could be that only this credit has to be given due.
	
	It is credited at:
	https://opus.nlpl.eu/CCMatrix/corpus/version/CCMatrix
	https://opus.nlpl.eu/NLLB/en&ta/v1/NLLB
		License: ODC-By
	
	Paper mentions (but it is not sure that data created from the paper were used):
		The underlying dataset was mined from CommonCrawl (Apache 2.0)

CCMatrix (citing)
	CCMatrix: Mining Billions of High-Quality Parallel Sentences on the WEB
	https://opus.nlpl.eu/CCMatrix/corpus/version/CCMatrix => citing 2 papers

CommonCrawl (C?)
	https://commoncrawl.org/terms-of-use
	Complicated, I can't tell so far

CCAligned (citing)
	CCAligned: A Massive Collection of Cross-Lingual Web-Document Pairs
	https://aclanthology.org/2020.emnlp-main.480/
	https://huggingface.co/datasets/ahelk/ccaligned_multilingual
	https://www.statmt.org/cc-aligned/
	created from 68 Commoncrawl Snapshots, so referring to ComonCrawl

EUbookshop (citing)
	https://opus.nlpl.eu/EUbookshop/corpus/version/EUbookshop
	
Gourmet (CC0)
	gourmet project at https://gourmet-project.eu
	License depends on the used data
	https://github.com/EdinburghNLP/gourmet-models
	CC-BY
	https://opus.nlpl.eu/GoURMET/corpus/version/GoURMET
	CC0

OPUS DGT (citing)
	https://joint-research-centre.ec.europa.eu/language-technology-resources/dgt-translation-memory_en#dgt-memory
	The DGT-TM database is the exclusive property of the European Commission. The Commission cedes its non-exclusive rights free of charge and world-wide for the entire duration of the protection of those rights to the re-user, for all kinds of use which comply with the conditions laid down in the Commission Decision of 12 December 2011 on the re-use of Commission documents, published in Official Journal of the European Union L330 of 14 December 2011, pages 39 to 42.
	Any re-use of the database or of the structured elements contained in it is required to be identified by the re-user, who is under an obligation to state the source of the documents used: the website address, the date of the latest update and the fact that the European Commission retains ownership of the data.
	
	Cite LREC 2012

OPUS EOPC (CC-BY-SA)
	https://opus.nlpl.eu/EOPC/corpus/version/EOPC
	cite tiedemann-2012-parallel

	Estonian Open Parallel Corpusd
	http://metashare.elda.org/repository/browse/estonian-open-parallel-corpus-2014-estonian-english/d12b8c9c7ef111e5aa3b001dd8b71c66bd5c7d10b0664e8490382a9b22f8fa97/
	CC-BY-SA

Krzysztof Wołk and Krzysztof Marasek: Building Subject-aligned Comparable Corpora and Mining it for Truly Parallel Sentence Pairs., Procedia Technology, 18, Elsevier, p.126-132, 2014
	https://doi.org/10.1016/j.protcy.2014.11.024
	wolk_marasek_building_2014
	Don't know why it is credited

Kashefi, O. (2018). MIZAN: a large persian-english parallel corpus. Computing Research Repository, arXiv:1801.02107.
	https://arxiv.org/abs/1801.02107
	https://github.com/omidkashefi/Mizan
	CC-BY
	
El-Kishky, Ahmed and Renduchintala, Adi and Cross, James and Guzmán, Francisco and Koehn, Philipp - XLEnt: Mining Cross-lingual Entities with Lexical-Semantic-Phonetic Word Alignment
	el-kishky-etal-2021-xlent
	
EMNLP 2020
	El-Kishky, Ahmed and Chaudhary, Vishrav and Guzmán, Francisco and Koehn, Philipp - Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing
	https://aclanthology.org/2020.emnlp-main.0/
	emnlp-2020-main

GlobalVoices (citing) 
	http://opus.nlpl.eu/GlobalVoices-2018Q4.php
	https://opus.nlpl.eu/GlobalVoices/corpus/version/GlobalVoices
	https://www.localprobook.com/article/CASMACAT.html
	Please cite the following article if you use any part of the corpus in your own work: J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012) 
	
MultiUN (cite)
	https://opus.nlpl.eu/CCMatrix/corpus/version/MultiUN
	Please cite MultiUN: A Multilingual corpus from United Nation Documents, Andreas Eisele and Yu Chen, LREC 2010
	Please cite the following article if you use any part of the corpus in your own work: J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012) 

News-Commentary (cite)
	https://opus.nlpl.eu/News-Commentary/corpus/version/News-Commentary
	Please cite the following article if you use any part of the corpus in your own work: J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012) 

QED (research only,cite)
	https://opus.nlpl.eu/QED/corpus/version/QED
	QED Corpus is made public for RESEARCH purpose only.
	Please cite
	
Tatoeba (credit)
	https://opus.nlpl.eu/Tatoeba/corpus/version/Tatoeba
	https://tatoeba.org/eng/terms_of_use
	CC-BY-2.0 FR, cite
	
TED2013 (BY-NC-ND)
	https://opus.nlpl.eu/TED2013/corpus/version/TED2013
	https://wit3.fbk.eu/
	BY-NC-ND non-commercial
	
TED2020 (BY-NC-ND)
	https://opus.nlpl.eu/TED2020/corpus/version/TED2020
	https://www.ted.com/about/our-organization/our-policies-terms/ted-talks-usage-policy
	BY-NC-ND non-commercial
	or, aquiring commercial license

NODALIDA 2017
	Roberts Rozis, Raivis Skadins, 2017, Tilde MODEL - Multilingual Open Data for EU Languages. Proceedings of the 21th Nordic Conference of Computational Linguistics NODALIDA 2017
	
Reimers, Nils and Gurevych, Iryna - Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation
	reimers-gurevych-2020-making

OPUS-MT
	https://github.com/Helsinki-NLP/OPUS-MT-train?tab=readme-ov-file
	CC-BY 4.0
	
# License type notes

Apache 2.0
	https://snyk.io/articles/apache-license/#apache-license-vs-mit
	
	https://www.tldrlegal.com/license/apache-license-2-0-apache-2-0
	You can do what you like with the software, as long as you include the required notices.
	
CC0
	public

CC-BY
	credit
	
CC-BY-SA
	Creative Commons Attribution Share Alike
	https://choosealicense.com/licenses/cc-by-sa-4.0/
	credit,share with same license
	
	https://en.wikipedia.org/wiki/Creative_Commons_license#Drauglis_v._Kappa_Map_Group,_LLC
	The judge dismissed the case on that count, ruling that the atlas was not a derivative work of the photograph in the sense of the license, but rather a collective work. Since the atlas was not a derivative work of the photograph, Kappa Map Group did not need to license the entire atlas under the CC BY-SA 2.0 license.
	
GFDL
	https://en.wikipedia.org/wiki/GNU_Free_Documentation_License
	rights to copy, redistribute, and modify
	
ODC-By
	Share, create, adapt, must attribute
	https://opendatacommons.org/licenses/by/summary/

# Overview

For these two models I see that they were trained also on data that is for non-commercial and research purposes only from TED talks:
English-Russian, Russian-English
One model does not have anything in the README: Spanish-Portugese

For the rest it is complicated:

1) models usually do not provide list of source or license of data, instead they provide needed citations required by source data, which is not always pointing to data. For example they refer to publication emnlp-2020-main which is not pointing to any data.

2) most of models state that they used "Data compiled by Opus" or "OPUS-MT" which may be various data components of OPUS corpora; OPUS contains also non-free data for example TED-talks or WikiMatrix and it is not known if it was or wasn't trained on it; But they state that model data are trained on a permissive license "CC-BY 4.0" so we can expect that it used only free data.

3) about half of language models are trained on WikiExtract, WikiMatrix data which has license CC-BY-SA saying "share with same license" but from my findings this applies only if we would be doing derivative of the work (use models to generate our new models), not when we do "collective work" on top of the models.
